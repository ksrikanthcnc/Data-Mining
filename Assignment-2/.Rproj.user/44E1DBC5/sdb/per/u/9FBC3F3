{
    "collab_server" : "",
    "contents" : "dat <- read.csv(\"data.csv\")\ndat <- dat[1:10000,]\nsummary(dat)\ncleandata <- dat\ncleandata <- na.omit(cleandata)\n\n#scaling\n\napply(cleandata,MARGIN = 2, FUN = function(x)sum(is.na(x)))\nmaxs    =   apply(cleandata,    MARGIN  =   2,  max)\nmins    =   apply(cleandata,    MARGIN  =   2,  min)\nscaledData =     as.data.frame(scale(cleandata, center  =   mins,   scale   =   maxs    - mins))\nsummary(scaledData)\n\n#Splitting data in 80:20 ratio\ntrain = sample(1:nrow(scaledData), nrow(scaledData)*0.8)\ntest = -train\ntraining_Data = scaledData[train,]\ntesting_Data = scaledData[test,]\ndim(training_Data)\ndim(testing_Data)\n\n#neural net\n\nlibrary(neuralnet)\nn   <- names(training_Data)\nf   <- as.formula(paste(\"Channel    ~\", paste(n[!n  %in%    \"Channel\"], collapse    =   \"   +   \")))\nneuralnet_Model <- neuralnet(f,data = training_Data, hidden = c(2,1))\nplot(neuralnet_Model)\nneuralnet_Model$result.matrix\npred_neuralnet<-compute(neuralnet_Model,testing_Data[,2:8])\npred_neuralnet.scaled   <- pred_neuralnet$net.result *(max(scaledData$Channel)-min(scaledData$Channel))+min(scaledData$Channel)\nreal.values <- (testing_Data$Channel)*(max(cleandata$Channel)-min(cleandata$Channel))+min(cleandata$Channel)\nMSE.neuralnetModel  <- sum((real.values - pred_neuralnet.scaled)^2)/nrow(testing_Data)\nMSE.neuralnetModel\nplot(real.values, pred_neuralnet.scaled, col='red',main='Real   vs  predicted',pch=18,cex=0.7)\nabline(0,1,lwd=2)\nlegend('bottomright',legend='NN',pch=18,col='red',  bty='n')",
    "created" : 1509291977625.000,
    "dirty" : true,
    "encoding" : "",
    "folds" : "",
    "hash" : "555382993",
    "id" : "9FBC3F3",
    "lastKnownWriteTime" : 80,
    "last_content_update" : 1509291979177,
    "path" : null,
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled2"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}